var documenterSearchIndex = {"docs":
[{"location":"examples/ss_double_integrator/#State-Feedback:-Double-Intergrator-with-Unknown-Sign","page":"State Feedback: Double Integrator","title":"State Feedback: Double Intergrator with Unknown Sign","text":"","category":"section"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"This recreates the controller from A. Rantzer, “Minimax adaptive control for a finite set of linear systems,” in Proc. 3th Annu. Learning Dyn. Control Conf., vol. 144, Jun. 07 – 08 2021, pp. 893–904.  See the arXiv version.","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"We consider a discrete-time double integrator with unknown input direction","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"    beginaligned\n        x_t+1  = beginbmatrix\n            2  -1  -1 \n            1  0  0 \n            0  0  0 \n        endbmatrix + \n        x_t pm\n        beginbmatrix\n            0  0  1\n        endbmatrix\n            u_t + \n            I w_t\n    endaligned","category":"page"},{"location":"examples/ss_double_integrator/#Preamble","page":"State Feedback: Double Integrator","title":"Preamble","text":"","category":"section"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"We load the packages","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"using MinimaxAdaptiveControl \nusing LinearAlgebra\nusing JuMP\nusing Plots\nusing Clarabel # Open source SDP solver","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"We use Clarabel here, but any JuMP compatible SDP solver will do.","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"Switch this out with whatever optimizer you are using","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"optimizer_factory = () -> Clarabel.Optimizer","category":"page"},{"location":"examples/ss_double_integrator/#System-definition","page":"State Feedback: Double Integrator","title":"System definition","text":"","category":"section"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"We define the system matrices, and the cost function","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"    sum_t = 0^infty left( x_t^2_Q + u_t^2_R - gamma^2 w_t^2 right)","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"where Q = I and R = I.","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"A0 = [\n    2.0 -1.0 1.0;\n    1.0 0.0 0.0;\n    0.0 0.0 0.0\n   ]\nB0 = [0.0; 0.0; 1.0;;]\nQ = Matrix(1.0I, 3, 3)\nR = Matrix(1.0I, 1, 1)\nγ = 19.0\nsys1 = SSLinMod(A0, B0, Q, R)\nsys2 = SSLinMod(A0, -B0, Q, R)\nsys = [sys1, sys2]","category":"page"},{"location":"examples/ss_double_integrator/#Reduction-to-principal-problem","page":"State Feedback: Double Integrator","title":"Reduction to principal problem","text":"","category":"section"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"We reduce the uncertain system sys to principal model form using reduceSys","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"models = [Model(optimizer_factory()), Model(optimizer_factory())]\n(A, B, G, Ks, Hs) = reduceSys(sys, γ, models)","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"Here we get the matrices","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"A = 0 quad B = 0 quad G = I","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"The feedback gains are","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"beginaligned\nK_1  = beginbmatrix 18  -13  13 endbmatrix \nK_2  = beginbmatrix -18  13  -13 endbmatrix\nendaligned","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"The cost matrices become","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"H_1 = beginbmatrix\n    -18040   7220  -7220   00  7220  3610    00\n    7220    -3600  3610    00  -3610   00    00\n    -7220   3610   -3600   00  3610    00    00\n    00       00     00    -3600   00    00  3610\n    7220    -3610  3610    00  -3610    00   00\n    3610     00     00     00   00  -3610   00\n    00       00     00    3610   00    00  -3610\nendbmatrix","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"and","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"H_2 = beginbmatrix\n    -18040   7220  -7220   00  7220  3610    00\n    7220    -3600  3610    00  -3610   00    00\n    -7220   3610   -3600   00  3610    00    00\n    00       00     00    -3600   00    00  -3610\n    7220    -3610  3610    00  -3610    00   00\n    3610     00     00     00   00  -3610   00\n    00       00     00    -3610   00    00  -3610\n    endbmatrix","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"They differ only in the elemets on the (4, 7)th and (7, 4)th elements.","category":"page"},{"location":"examples/ss_double_integrator/#Controller-synthesis","page":"State Feedback: Double Integrator","title":"Controller synthesis","text":"","category":"section"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"We first ensure that the associated performance level and feedback gains solves the Bellman inequalities using MACLMIs","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"model = Model(optimizer_factory())\nperiod = 1\nPs0, Psplus= MACLMIs(A, B, G, Ks, Hs, period, model)","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"and verify the termination status of the optimization routine","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"julia>\ntermination_status(model)\nOPTIMAL::TerminationStatusCode = 1","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"Next we construct the selection rule and controller objects using getPeriodicSelectionRule and MAController:","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"selectionRule = getPeriodicSelectionRule(period)\nN = length(Hs)\nmac = MAController(zeros(3), A, B, G, Ks, Hs, zeros(N), selectionRule)","category":"page"},{"location":"examples/ss_double_integrator/#Simulation","page":"State Feedback: Double Integrator","title":"Simulation","text":"","category":"section"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"We first set up the matrices holding the states, outputs, control signal and disturbances","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"Tdur = 2000\nstates = zeros(Tdur + 1, 3)\noutputs = zeros(Tdur + 1, 3)\ncontrols = zeros(Tdur, 1)\nprocessDisturbances = randn(Tdur, 3)\nmeasurementDisturbances = zeros(Tdur, 3)","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"We also want to track the time-evolution of the value-function and the empirical ell_2-gain using getValueFunction and InducedlpGain","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"vfun = getValueFunction(mac, Ps0, N)\ndc= InducedlpGain(0.0, 0.0, 0.0, 2)\nmetrics = [vfun, dc]\nmetricResults = zeros(Tdur + 1, length(metrics))","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"Next we construct the SSPlant for data generation and simulate!","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"plant = SSPlant(A0, -B0, zeros(3))\nsimulate!(states, outputs, controls, processDisturbances, measurementDisturbances, metricResults, metrics, plant, mac, Tdur)","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"and plot the results","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"plot(\n     [states[1:Tdur, 1] controls[1:Tdur] metricResults[1:Tdur, :]], layout = (2, 2),\n     xlabel = \"Timestep\",\n     ylabel = [\"State 1\" \"Control\" \"Value Function\" \"Induced Lp Gain\"],\n     legend = false,\n     linewidth = 2\n    )","category":"page"},{"location":"examples/ss_double_integrator/","page":"State Feedback: Double Integrator","title":"State Feedback: Double Integrator","text":"(Image: image)","category":"page"},{"location":"api/#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"Pages = [\"reduction.md\"]","category":"page"},{"location":"lib/reduction/#Reduction-related-functions","page":"Reduction","title":"Reduction-related functions","text":"","category":"section"},{"location":"lib/reduction/#Functions","page":"Reduction","title":"Functions","text":"","category":"section"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"bared\nfared\nreduceSys","category":"page"},{"location":"lib/reduction/#MinimaxAdaptiveControl.bared","page":"Reduction","title":"MinimaxAdaptiveControl.bared","text":"bared(Ahat::AbstractMatrix{T}, Bhat::AbstractMatrix{T}, Ghat::AbstractMatrix{T}, H::AbstractMatrix{T}, model::GenericModel{T}) where T <: Real\nbared(Ahat::AbstractMatrix{T}, Bhat::AbstractMatrix{T}, Ghat::AbstractMatrix{T}, H::AbstractMatrix{T}; method::Symbol = :Laub, iters::Int = 1000) where T <: Real\n\nSolves the backward algebraic Riccati equation using the specified method.\n\nArguments\n\nAhat::AbstractMatrix{T}: State transition matrix.\nBhat::AbstractMatrix{T}: Control input matrix.\nGhat::AbstractMatrix{T}: Disturbance input matrix.\nH::AbstractMatrix{T}: Cost matrix, symmetric.\nmodel::GenericModel{T}: JuMP optimization model.\nmethod::Symbol: Method to be used for solving the Riccati equation (default is :Laub). The available options are :Laub and :Iterate, see Details on the backward algebraic riccati equation for more information.\niters::Int: Number of iterations for the iterative method (default is 1000).\n\nReturns\n\nA tuple containing:\nP::Matrix{T}: Backward riccati solution matrix, positive definite.\nK::Matrix{T}: Gain matrix.\ntermination_status::Symbol: Status of the optimization.\n\n\n\n\n\n","category":"function"},{"location":"lib/reduction/#MinimaxAdaptiveControl.fared","page":"Reduction","title":"MinimaxAdaptiveControl.fared","text":"fared(sys::OFLinMod{T}, γ::Real, model::GenericModel{T}; method::Symbol = :LMI2) where T <: Real\nfared(sys::OFLinMod{T}, γ::Real; method::Symbol = :Iterate, iters::Int = 1000) where T <: Real\nfared(A::AbstractMatrix{T}, B::AbstractMatrix{T}, C::AbstractMatrix{T}, D::AbstractMatrix{T}, G::AbstractMatrix{T}, Q::AbstractMatrix{T}, R::AbstractMatrix{T}, γ::Real, model::GenericModel{T}; method = :LMI2) where T <: Real\nfared(A::AbstractMatrix{T}, B::AbstractMatrix{T}, C::AbstractMatrix{T}, D::AbstractMatrix{T}, G::AbstractMatrix{T}, Q::AbstractMatrix{T}, R::AbstractMatrix{T}, γ::Real; method = :Iterate, iters = 1000) where T <: Real\n\nSolves the forward algebraic Riccati equation for an output-feedback linear model (or the given system matrices) using the specified method.\n\nArguments\n\nsys::OFLinMod{T}: Output-feedback linear model.\nA::AbstractMatrix{T}: State transition matrix.\nB::AbstractMatrix{T}: Control input matrix.\nC::AbstractMatrix{T}: Output matrix.\nD::AbstractMatrix{T}: Measurement noise matrix.\nG::AbstractMatrix{T}: Disturbance input matrix.\nQ::AbstractMatrix{T}: State cost matrix.\nR::AbstractMatrix{T}: Control input cost matrix.\nγ::Real: Induced ell_2-gain\nmodel::GenericModel{T}: Generic optimization model.\nmethod::Symbol: Method to be used for solving the Riccati equation (default is :LMI2 or :Iterate depending on the function signature). The options are :LMI1, :LMI2, :Iterate, and :Laub. See Details on the forward algebraic riccati equation for more information.\niters::Int: Number of iterations for the iterative method (default is 1000).\n\nReturns\n\nA tuple containing:\nS::Matrix{T}: Forward riccati solution matrix, positive definite.\nAhat::Matrix{T}: Observer state transition matrix.\nGhat::Matrix{T}: Observer output injection matrix.\nH::Matrix{T}: Cost matrix.\ntermination_status::Symbol: Status of the optimization.\n\n\n\n\n\n","category":"function"},{"location":"lib/reduction/#MinimaxAdaptiveControl.reduceSys","page":"Reduction","title":"MinimaxAdaptiveControl.reduceSys","text":"reduceSys(sys::Vector{SSLinMod{T}}, γ::T, models::AbstractVector{GenericModel{T}}) where T<: Real\n\nThe function computes the aggregated model matrices (Ahat, Bhat, Ghat) and the gain (Ks) and auxiliary (Hs) matrices for each of the input models.\n\nReduces state-feedback adaptive control with uncertain parameters\n\n    beginaligned\n        x_t+1  = Ax_t + Bu_t + w_t \n        (A B)  in (A_1 B_1) ldots (A_M B_M)\n    endaligned\n\nwith the soft-constrained objective function\n\n    min_umax_w N A Bsum_t=0^Nleft( x_t^2_Q + u_t^2_R - gamma^2 w_t^2 right)\n\nto a certain system\n\n    beginaligned\n        z_t + 1  = hat Az_t + hat Bu_t + hat G d_t\n    endaligned\n\nwith uncertain objective\n\nmin_u max_H d N sum_t = 0^N sigma_H(z_t u_t d_t)\n\nArguments\n\nsys::Vector{SSLinMod{T}}: Vector of state-space linear models to be reduced.\nγ::T: Induced ell_2-gain.\nmodels::AbstractVector{GenericModel{T}}: Vector of JuMP models, one per state-space model.\n\nReturns\n\nAhat::Matrix{T}: Aggregated state transition matrix.\nBhat::Matrix{T}: Aggregated control input matrix.\nGhat::Matrix{T}: Aggregated disturbance input matrix.\nKs::Vector{Matrix{T}}: Vector of gamma-suboptimal mathcal H_infty gain matrices.\nHs::Vector{Matrix{T}}: Vector of cost weights.\n\nreduceSys(sys::Vector{OFLinMod{T}}, γ::T, models::AbstractVector{GenericModel{T}}, method::Symbol = :LMI2) where T <: Real\n\nReduces a set of output-feedback linear models into a single aggregated model using a specified method. The function computes the aggregated model matrices (Ahat, Bhat, Ghat) and the gain (Ks) and auxiliary (Hs) matrices for each of the input models.\n\nTakes uncertain systems of the form\n\nbeginaligned\n\t\tx_t + 1  = A x_t + B u_t + Gw_tquad  t geq 0 \n\t\ty_t  = C x_t + D v_t \n                (A B C D G)  in mathcal M\nendaligned\n\nwith soft-constrained objective function\n\n    min_umax_w v x_0 N M in mathcal Msum_t=0^Nleft( x_t^2_Q + u_t^2_R - gamma^2 (w_t v_t)^2 right) - x_0 - hat x_0^2_S_M 0\n\nto a certain system\n\n    beginaligned\n        z_t + 1  = hat Az_t + hat Bu_t + hat G d_t\n    endaligned\n\nwith uncertain objective\n\nmin_u max_H d N sum_t = 0^N sigma_H(z_t u_t d_t)\n\nArguments\n\nsys::Vector{OFLinMod{T}}: Vector of output-feedback linear models to be reduced.\nγ::T: Induced ell_2-gain.\nmodels::AbstractVector{GenericModel{T}}: Vector of JuMP models, one for each ouput-feedback model\nmethod::Symbol: Method to be used for the reduction (default is :LMI2). See fared\n\nReturns\n\nA::Matrix{T}: Aggregated observer state transition matrix.\nB::Matrix{T}: Aggregated observer control input matrix.\nG::Matrix{T}: Aggregated observer measurement input matrix.\nKs::Vector{Matrix{T}}: Vector of gamma-suboptimal mathcal H_infty observer gain matrices.\nHs::Vector{Matrix{T}}: Vector of cost weights.\n\n\n\n\n\n","category":"function"},{"location":"lib/reduction/#Details-on-the-forward-algebraic-riccati-equation","page":"Reduction","title":"Details on the forward algebraic riccati equation","text":"","category":"section"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"Given matrices A in mathbbR^n_x times n_x, C in mathbbR^n_x times n_y, D in mathbbR^n_y times n_v, G in mathbbR^n_x times n_w, Q in mathbbR^n_x times n_x, R in mathbbR^n_u times n_u, and gamma  0 the discrete-time forward algebraic Riccati equation (FARED) is defined as.","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"beginaligned\n    S  = (AX^-1A^top + gamma^-2GG^top)^-1 \n    X  = S + gamma^2 C^top (DD^top)^-1C - Q \n    L  = gamma^2 AX^-1C(DD^top)^-1\nendaligned","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"The FARED may have multiple solutions. The function fared computes the solution associated with the maximal S (over the positive semidefinite cone). The function also returns a matrix H which is given by","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"beginbmatrix\n    SX^-1S -S  0  gamma^2 SX^-1C(DD^top)^-1 \n    0  R  0 \n    gamma^2 C^top X^-1S(DD^top)^-1  0  -left((DD^top)^-1 + C(S - Q)^-1C^topright)^-1\n    endbmatrix","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"The observer matrices are constructed by hat A = A X^-1 S and hat G = gamma^2 A X^-1 C (DD^top)^-1.","category":"page"},{"location":"lib/reduction/#fared-:LMI1","page":"Reduction","title":"fared :LMI1","text":"","category":"section"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"Solves (if possible) the SDP","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"beginaligned\n    textmaximize  quad texttrace(S) \n    textsubject to  quad beginbmatrix\n        S  SA  SG \n        A^top S  X  0_n_x times n_w \n        G^top S  0_n_w times n_x  gamma^2 I_n_w\n    endbmatrix succeq 0 \n     quad X = S + gamma^2 C^top (DD^top)^-1C - Q\nendaligned","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"where S is the decision variable. The function returns the optimal S and the corresponding X, L, and H.","category":"page"},{"location":"lib/reduction/#fared-:LMI2","page":"Reduction","title":"fared :LMI2","text":"","category":"section"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"Directly constructs an SDP whose solution gives the optimal (S hat A hat G H).  Let ","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"Y = beginbmatrix\n        I_n_x  0 \n        0  C^top \n        0  0 \n        0  D^top\n    endbmatrix","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"The SDP is given by","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"beginaligned\n    undersetS hat A hat B Htextminimize  quad texttrace(H) \n    textsubject to  quad beginbmatrix\n        S  -S  0  0  -hat A^top \n        -S  S - Q  0  0  A^top S - C^top hat G \n        0  0  gamma^2 I_n_w  0  G^top S \n        0  0  0  gamma^2 I_n_v  -hat G^top \n        -hat A  A^top S  G  -G  -hat G D S\n    endbmatrix -\n    beginbmatrix\n        Y H Y^top  0 \n        0  0\n    endbmatrix succeq 0\n     S succeq 0 \n     H - H^top = 0\n    endaligned","category":"page"},{"location":"lib/reduction/#fared-:Iterate","page":"Reduction","title":"fared :Iterate","text":"","category":"section"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"This method solves the FARED by iterating starting with S_0 = gamma^2 I_n_x. The iteration is given by","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"beginaligned\n    S_t + 1 = (AX_t^-1A^top + gamma^-2GG^top)^-1 \n    X_t  = S_t + gamma^2 C^top (DD^top)^-1C - Q\nendaligned","category":"page"},{"location":"lib/reduction/#fared-:Laub","page":"Reduction","title":"fared :Laub","text":"","category":"section"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"Uses MatrixEquations.jl function ared to solve the FARED. ared implements W. F. Arnold and A. J. Laub, \"Generalized eigenproblem algorithms and software for algebraic Riccati equations,\" in Proceedings of the IEEE, vol. 72, no. 12, pp. 1746-1754, Dec. 1984, doi: 10.1109/PROC.1984.13083.","category":"page"},{"location":"lib/reduction/#Details-on-the-backward-algebraic-riccati-equation","page":"Reduction","title":"Details on the backward algebraic riccati equation","text":"","category":"section"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"Fix gamma  0 and consider the transformation","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"\tbeginaligned\n\t\tG(gamma)  = gammahat Gsqrt-H^-dd qquad\n\t\tR = H^uu - H^udH^-ddH^du \nQ  = H^dd - H^zdH^-ddH^dz\n   qquad -(H^zu - H^zdH^-dd H^du)R^-1(*) \n\tA  = hat A - BR^-1(H^zu - H^zdH^-ddH^du) \n\t\t   quad - GH^-ddleft(H^dz - H^duR^-1left(H^uz - H^udH^-ddH^dzright)right)\n\t\tB  = hat B - G(H^dd)^-1H^du\n\tendaligned","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"As we are interested in the upper value, d_t is allowed to depend causally on z and u, but u is required to depend strictly causally on d. The following parameterization of d_t and u_t respect the causalilty structure of the problem,","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"beginaligned\n\td_t  = -H^-dd(H^dzz_t + H^duu_t) + gammasqrt-H^-dddelta_t quad t geq 0 \nu_t  = -R^-1(H^uz - H^udH^-ddH^dz)z_t + v_t quad t geq 0 \nendaligned","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"and leads to the follow equivalent dynamic game. Compute","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"\tinf_nusup_delta N sum_t=0^N-1 left( z_t^2_Q + v_t^2_R - gamma^2delta_t^2right)","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"subject to the dynamics","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"beginaligned\n\tz_t + 1  = Az_t + Bv_t + G(gamma)delta_t quad t geq 0 \n\tv_t  = nu_t(z_0 ldots z_t) quad t geq 0\nendaligned","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"This reformulation puts the problem on standard gamma-suboptimal Hinf form, and the value function, if bounded, is well known to be a quadratic function of the initial state, and the optimal controller is of the form v_t = -K_dagger z_t.","category":"page"},{"location":"lib/reduction/","page":"Reduction","title":"Reduction","text":"The value function, V_star(z_0), has the form V_star(z_0) = z_0^2_P_star, where P_star is the minimal fixed point of the generalized algebraic riccati equation.  P_star and K_dagger and can be computed, for example, through value iteration, Arnold and Laub's Schur methods and convex optimization.","category":"page"},{"location":"lib/constructors/","page":"Constructors","title":"Constructors","text":"Pages = [\"constructors.md\"]","category":"page"},{"location":"lib/constructors/","page":"Constructors","title":"Constructors","text":"InducedlpGain\nMAController\nOFLinMod\nOFPlant\nRecursiveELS\nSSLinMod\nSSPlant\nSelfTuningLQG\nValueFunction\nstateObserver","category":"page"},{"location":"lib/constructors/#MinimaxAdaptiveControl.InducedlpGain","page":"Constructors","title":"MinimaxAdaptiveControl.InducedlpGain","text":"InducedlpGain{T, N<:Integer}\n\nPerformance metric based on induced l_p gain.\n\nFields\n\nvalue::T: Value of the induced l_p gain.\nsumpOutput::T: Sum of the p-norm of the output to the p-th power.\nsumpInput::T: Sum of the p-norm of the input to the p-th power.\np::N: Order of the norm.\n\n\n\n\n\n","category":"type"},{"location":"lib/constructors/#MinimaxAdaptiveControl.MAController","page":"Constructors","title":"MinimaxAdaptiveControl.MAController","text":"MAController{T}\n\nMinimax Adaptive Switching Controller for the system\n\nbeginaligned\n        z_t + 1  = hat A z_t + hat B u_t + hat G d_t t geq 0 \n        u_t  = K_t z_t\nendaligned\n\nwith the uncertain objective\n\nJ = min_u max_d N H sum_t = 0^infty sigma_H(z_t u_t d_t)\n\nwhere z_t is the state vector, u_t is the control input vector and d_t is measured disturbance vector. The function sigma_H is a quadratic function of the form ```math \\begin{aligned}         \\sigmaH(zt, ut, dt) = \\begin{bmatrix} zt \\ ut \\ dt \\end{bmatrix}^T H \\begin{bmatrix} zt \\ ut \\ dt \\end{bmatrix}. \\end{aligned}\n\nselectionRule is a (possibly stateful) function that selects the control action based on rs and the current state.\n\nFields\n\nz::AbstractVector{T}: State vector of the controller.\nAhat::AbstractMatrix{T}: State transition matrix.\nBhat::AbstractMatrix{T}: Estimated control input matrix.\nGhat::AbstractMatrix{T}: Estimated disturbance input matrix.\nKs::AbstractVector{Matrix{T}}: Feedback gains, one for each mode.\nHs::AbstractVector{Matrix{T}}: Quadratic cost matrices, one for each mode.\nrs::AbstractVector{T}: Worst-case historically incurred costs\nselectionRule::Function: Function for selecting the control action.\n\n\n\n\n\n","category":"type"},{"location":"lib/constructors/#MinimaxAdaptiveControl.OFLinMod","page":"Constructors","title":"MinimaxAdaptiveControl.OFLinMod","text":"OFLinMod{T}\n\nOutput-feedback representation of the linear model\n\nbeginaligned\n\t\tx_t + 1  = A x_t + B u_t + Gw_tquad  t geq 0 \n\t\ty_t  = C x_t + D v_t\nendaligned\n\nwith cost function\n\n        J = sum_t = 0^infty left( x_t^T Q x_t + u_t^T R u_t right)\n\nFields\n\nA::AbstractMatrix{T}: State transition matrix.\nB::AbstractMatrix{T}: Control input matrix.\nG::AbstractMatrix{T}: Disturbance input matrix.\nC::AbstractMatrix{T}: Output matrix.\nD::AbstractMatrix{T}: Feedforward matrix.\nQ::AbstractMatrix{T}: State cost matrix.\nR::AbstractMatrix{T}: Control input cost matrix.\n\n\n\n\n\n","category":"type"},{"location":"lib/constructors/#MinimaxAdaptiveControl.OFPlant","page":"Constructors","title":"MinimaxAdaptiveControl.OFPlant","text":"OFPlant{T}\n\nOutput-feedback representation of a plant of the form\n\nbeginaligned\n\t\tx_t + 1  = A x_t + B u_t + Gw_tquad  t geq 0 \n\t\ty_t  = C x_t + D v_t\nendaligned\n\nFields\n\nA::AbstractMatrix{T}: State transition matrix.\nB::AbstractMatrix{T}: Control input matrix.\nG::AbstractMatrix{T}: Disturbance input matrix.\nC::AbstractMatrix{T}: Output matrix.\nD::AbstractMatrix{T}: Noise Feedforward matrix.\nx::AbstractVector{T}: State vector.\n\n\n\n\n\n","category":"type"},{"location":"lib/constructors/#MinimaxAdaptiveControl.RecursiveELS","page":"Constructors","title":"MinimaxAdaptiveControl.RecursiveELS","text":"RecursiveELS{T}\n\nExtended Least Squares (ELS) estimator for recursive parameter estimation.\n\nFields\n\nparameterEstimates::Vector{T}: Vector of current parameter estimates.\ninverseErrorCovariance::Matrix{T}: Inverse of the error covariance matrix.\nregressors::Vector{T}: Vector of regressor values.\nny::Int: Number of outputs.\nnu::Int: Number of inputs.\nne::Int: Number of errors.\nregularization::T: Regularization parameter for numerical stability.\n\n\n\n\n\n","category":"type"},{"location":"lib/constructors/#MinimaxAdaptiveControl.SSLinMod","page":"Constructors","title":"MinimaxAdaptiveControl.SSLinMod","text":"SSLinMod{T}\n\nState-space representation of the linear model\n\n        x_t + 1 = A x_t + B u_t t geq 0\n\nwith cost function\n\n        J = sum_t = 0^infty left( x_t^T Q x_t + u_t^T R u_t right)\n\nFields\n\nA::AbstractMatrix{T}: State transition matrix.\nB::AbstractMatrix{T}: Control input matrix.\nQ::AbstractMatrix{T}: State cost matrix.\nR::AbstractMatrix{T}: Control input cost matrix.\n\n\n\n\n\n","category":"type"},{"location":"lib/constructors/#MinimaxAdaptiveControl.SSPlant","page":"Constructors","title":"MinimaxAdaptiveControl.SSPlant","text":"SSPlant{T}\n\nState-space representation of the plant:\n\nbeginaligned\n        x_t + 1  = A x_t + B u_t + w_t t geq 0\nendaligned\n\nwhere x_t is the state vector, u_t is the control input vector, and w_t is the disturbance vector.\n\nFields\n\nA::AbstractMatrix{T}: State transition matrix.\nB::AbstractMatrix{T}: Control input matrix.\nx::AbstractVector{T}: State vector.\n\n\n\n\n\n","category":"type"},{"location":"lib/constructors/#MinimaxAdaptiveControl.SelfTuningLQG","page":"Constructors","title":"MinimaxAdaptiveControl.SelfTuningLQG","text":"SelfTuningLQG(A0::Matrix{T}, K0::Matrix{T}, C0::Matrix{T}, B0::Matrix{T}, xhat0::Vector{T},                    regularization::T, ρ::T, nu::Int) where T\n\nInitialize the self-tuning LQG controller.\n\nArguments\n\nA0::Matrix{T}: Initial state transition matrix.\nK0::Matrix{T}: Initial Kalman gain matrix.\nC0::Matrix{T}: Initial measurement matrix.\nB0::Matrix{T}: Initial control input matrix.\nxhat0::Vector{T}: Initial state estimate.\nregularization::T: Regularization parameter for numerical stability.\nρ::T: Regularization parameter for the Riccati equation.\nnu::Int: Number of control inputs.\n\nReturns\n\nSelfTuningLQG{T}: Initialized self-tuning LQG controller.\n\n\n\n\n\n","category":"type"},{"location":"lib/constructors/#MinimaxAdaptiveControl.ValueFunction","page":"Constructors","title":"MinimaxAdaptiveControl.ValueFunction","text":"ValueFunction{T}\n\nValue function for an optimal control problem.\n\nFields\n\nvalue::T: Value of the function.\nPs::AbstractVector{Matrix{T}}: Sequence of cost-to-go matrices.\nweights::AbstractVector{Vector{T}}: Sequence of weights.\ncontroller::MAController{T}: Associated minimax adaptive controller.\n\n\n\n\n\n","category":"type"},{"location":"lib/constructors/#MinimaxAdaptiveControl.stateObserver","page":"Constructors","title":"MinimaxAdaptiveControl.stateObserver","text":"stateObserver{T}\n\nState observer, also known as a Kalman Filter, for estimating the state of a system.\n\nFields\n\nA::Matrix{T}: State transition matrix.\nK::Matrix{T}: Kalman gain matrix.\nC::Matrix{T}: Measurement matrix.\nB::Matrix{T}: Control input matrix.\nxhat::Vector{T}: Estimated state vector.\n\n\n\n\n\n","category":"type"},{"location":"lib/str/#Self-Tuning-LQG-Controller-Documentation","page":"Self-tuning Regulator","title":"Self-Tuning LQG Controller Documentation","text":"","category":"section"},{"location":"lib/str/","page":"Self-tuning Regulator","title":"Self-tuning Regulator","text":"Pages = [\"bellman.md\"]","category":"page"},{"location":"lib/str/#Functions","page":"Self-tuning Regulator","title":"Functions","text":"","category":"section"},{"location":"lib/str/","page":"Self-tuning Regulator","title":"Self-tuning Regulator","text":"compute(controller::SelfTuningLQG{T}) where T\nupdate!(estimator::RecursiveELS{T}, output::T, input::T) where T\nupdate!(controller::SelfTuningLQG{T}, output::Vector{T}, input::Vector{T}; n = 1000) where T","category":"page"},{"location":"lib/str/#MinimaxAdaptiveControl.compute-Union{Tuple{SelfTuningLQG{T}}, Tuple{T}} where T","page":"Self-tuning Regulator","title":"MinimaxAdaptiveControl.compute","text":"compute(controller::SelfTuningLQG{T}) where T\n\nCompute the control input for the Self-Tuning LQG controller.\n\nArguments\n\ncontroller::SelfTuningLQG{T}: The Self-Tuning LQG controller.\n\nReturns\n\nVector{T}: The computed control input.\n\n\n\n\n\n","category":"method"},{"location":"lib/str/#MinimaxAdaptiveControl.update!-Union{Tuple{T}, Tuple{RecursiveELS{T}, T, T}} where T","page":"Self-tuning Regulator","title":"MinimaxAdaptiveControl.update!","text":"update!(estimator::RecursiveELS{T}, output::T, input::T) where T\n\nUpdate the Recursive ELS estimator with new output and input data.\n\nArguments\n\nestimator::RecursiveELS{T}: The Recursive ELS estimator to be updated.\noutput::T: The new output measurement.\ninput::T: The new input measurement.\n\nReturns\n\nT: The posteriori prediction error after updating the estimator.\n\n\n\n\n\n","category":"method"},{"location":"lib/str/#MinimaxAdaptiveControl.update!-Union{Tuple{T}, Tuple{SelfTuningLQG{T}, Vector{T}, Vector{T}}} where T","page":"Self-tuning Regulator","title":"MinimaxAdaptiveControl.update!","text":"update!(controller::SelfTuningLQG{T}, output::Vector{T}, input::Vector{T}; n = 1000) where T\n\nUpdate the Self-Tuning LQG controller with new output and input data.\n\nArguments\n\ncontroller::SelfTuningLQG{T}: The Self-Tuning LQG controller to be updated.\noutput::Vector{T}: The new output measurement vector.\ninput::Vector{T}: The new input measurement vector.\nn::Int: Number of Riccati equation steps to perform (default: 1000).\n\n\n\n\n\n","category":"method"},{"location":"examples/ss_delayed_integrator/#State-Feedback-Delayed-Integrator-Example","page":"State Feedback Delayed Integrator","title":"State-Feedback Delayed Integrator Example","text":"","category":"section"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"We will study two instances of the first-order delayed integrator where the gain has unknown sign","category":"page"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"y_t = y_t-1 + iu_t-2 + v_t-1","category":"page"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"where i = pm 1. By storing the previous input signal, we can design state-feedback controllers. Consider the two implementations","category":"page"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"beginaligned\n    x_t+1  = underbracebeginbmatrix\n        1  i  0  0\n    endbmatrix_A_i x_t + underbracebeginbmatrix 0  1 endbmatrix_B \n    x_t+1  = underbracebeginbmatrix\n        1  1  0  0\n    endbmatrix_A x_t + underbracebeginbmatrix 0  i endbmatrix_B_i\nendaligned\n","category":"page"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"We will refer to these models as A_i and B_i respectively. In the B_i model, the sign of  the gain is revealed immediately upon applying the control signal, while in A_i the uncertainty is revealed through the delayed effect on the first state. We will proceed to design minimax adaptive controllers with periodic switching for these two systems, and compare the gain bounds.","category":"page"},{"location":"examples/ss_delayed_integrator/#Prerequisites","page":"State Feedback Delayed Integrator","title":"Prerequisites","text":"","category":"section"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"Load the following packages","category":"page"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"using MinimaxAdaptiveControl\nusing LinearAlgebra\nusing JuMP\nusing Plots\nusing Clarabel # Optimization solver","category":"page"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"We are using Clarabel.jl, but any SDP solver JuMP.jl will do.  See the following list.","category":"page"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"We define an auxillary function to pass the optimizer_factory to JuMP's Model constructor.  Just substitute this with whatever solver you want to use.","category":"page"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"optimizer_factory=() -> Hypatia.Optimizer","category":"page"},{"location":"examples/ss_delayed_integrator/#State-feedback-models","page":"State Feedback Delayed Integrator","title":"State-feedback models","text":"","category":"section"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"We will define A_i and B_i as vectors, eaching containing two SSLinMod objects.","category":"page"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"# Define Ai system\nA1 = [1. 1; 0 0]\nA2 = [1. -1; 0 0]\nB0 = [0 1.]'\nQ = [1.0 0; 0 1.0]\nR = fill(1.0,1,1)\nsys1 = SSLinMod(A1, B0, Q, R)\nsys2 = SSLinMod(A2, B0, Q, R)\nsyssAi = [sys1, sys2]\n\n# Define Bi system\nA0 = [1. 1; 0 0]\nB0 = [0 1.]'\nsys3 = SSLinMod(A0, B0, Q, R)\nsys4 = SSLinMod(A0, -B0, Q, R)\nsyssBi = [sys3, sys4]","category":"page"},{"location":"examples/ss_delayed_integrator/#Bisection","page":"State Feedback Delayed Integrator","title":"Bisection","text":"","category":"section"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"The procedure for synthesizing controllers depends on a candidate ell_2-gain level gamma. In order to find the smallest gamma, we will use bisection. We construct this bisection in two parts. The function attemptMACLMIs(syss, γ, T) takes a vector of systems, performs the reduction with reduceSys and attempts to solve the periodic bellman inequality LMIs with period T using MACLMIs.","category":"page"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"function attemptMACLMIs(syss, γ, T)\n    N = length(syss)\n    models = [Model(optimizer_factory()) for i = 1:N]\n    set_silent.(models)\n    (A, B, G, Ks, Hs) = reduceSys(syss, γ, models)\n    model = Model(optimizer_factory())\n    set_silent(model)\n    Ps0, Psplus= MACLMIs(A, B, G, Ks, Hs, T, model)\n    return termination_status(model)\nend","category":"page"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"Next, we implement a bisection algorithm to find the smallest gamma for which we can solve the LMIs.","category":"page"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"warn: Numerics\nSome solvers can run into numerical issues when gamma or the period becomes large.","category":"page"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"function bisect(syss, fun, T; gammamin = 1.0, gammamax = 500.0, tol = 1e-3)\n    γmin = gammamin\n    γmax = gammamax\n    if fun(syss, gammamax, T) != MOI.OPTIMAL\n        error(\"gammamax is not feasible\")\n    end\n    while γmax - γmin > tol\n        γ = (γmin + γmax) / 2\n        if fun(syss, γ, T) == MOI.OPTIMAL\n            γmax = γ\n        else\n            γmin = γ\n        end\n    end\n    return γmax\nend","category":"page"},{"location":"examples/ss_delayed_integrator/#Results","page":"State Feedback Delayed Integrator","title":"Results","text":"","category":"section"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"We run the bisection algorithm for the two systems with periods from 1 to 8, setting gamma = -1 if the optimization problem is infeasible.","category":"page"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"Tmax = 8\ngammamins = zeros(Tmax, 2)\nfor t = 1:Tmax\n    try\n        gammamins[t, 1] = bisect(syssAi, attemptMACLMIs, t)\n    catch\n        gammamins[t, 1] = -1\n    end\n    try\n        gammamins[t, 2] = bisect(syssBi, attemptMACLMIs, t)\n    catch\n        gammamins[t, 2] = -1\n    end\nend","category":"page"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"The resulting gain-bounds are","category":"page"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"Period gamma_A_i gamma_B_i\n1 -1 5.8\n2 11.2 9.2\n3 13.9 14.0\n4 17.8 21.3\n5 22.7 32.0\n6 29.2 48.1\n7 37.4 72.3\n8 48.0 108.5","category":"page"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"We can plot them nicely using e.g. PyPlot.","category":"page"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"pyplot()\nplot(\n     gammamins, \n     seriestype=:scatter, \n     marker=[:x :o], \n     markersize = 8,\n    label = [\"A\" \"B\"],\n    xlabel = \"Period τ\",\n    ylabel = \"Gain bound γ\"\n   )","category":"page"},{"location":"examples/ss_delayed_integrator/","page":"State Feedback Delayed Integrator","title":"State Feedback Delayed Integrator","text":"(Image: image)","category":"page"},{"location":"lib/bellman/","page":"Bellman Inequalities","title":"Bellman Inequalities","text":"Pages = [\"bellman.md\"]","category":"page"},{"location":"lib/bellman/","page":"Bellman Inequalities","title":"Bellman Inequalities","text":"MACLMIs\ncompute(controller::MAController{T}) where T<:Real\ngetPeriodicSelectionRule\ngetValueFunction\nupdate!(controller::MAController{T}, output::AbstractVector{T}, control::AbstractVector{T}) where T<:Real","category":"page"},{"location":"lib/bellman/#MinimaxAdaptiveControl.MACLMIs","page":"Bellman Inequalities","title":"MinimaxAdaptiveControl.MACLMIs","text":"MACLMIs(A::AbstractMatrix{T}, B::AbstractMatrix{T}, G::AbstractMatrix{T}, Ks::AbstractVector{M}, \n        Hs::AbstractVector{M}, period::Int, model::Model) where M<:AbstractMatrix{T} where T<:Real\n\nSolve the Linear Matrix Inequalities (LMIs) associated with the periodic dissipation inequality for the given system matrices and optimization model.\n\nArguments\n\nA::AbstractMatrix{T}: State transition matrix of the system.\nB::AbstractMatrix{T}: Control input matrix of the system.\nG::AbstractMatrix{T}: Disturbance input matrix of the system.\nKs::AbstractVector{M}: Vector of feedback-gain matrices.\nHs::AbstractVector{M}: Vector of symmetric cost matrices.\nperiod::Int: Control period.\nmodel::Model: JuMP optimization optimization model.\n\nReturns\n\nPs0::Dict{NTuple{2, Int}, Array{VariableRef, 2}}: Dictionary of positive semi-definite matrices at time 0.\nPsplus::Dict{NTuple{4, Int}, Array{VariableRef, 2}}: Dictionary of positive semi-definite matrices at future time steps.\n\n\n\n\n\n","category":"function"},{"location":"lib/bellman/#MinimaxAdaptiveControl.compute-Union{Tuple{MAController{T}}, Tuple{T}} where T<:Real","page":"Bellman Inequalities","title":"MinimaxAdaptiveControl.compute","text":"compute(controller::MAController{T}) where T<:Real\n\nCompute the control input for the multi-agent controller.\n\nArguments\n\ncontroller::MAController{T}: The multi-agent controller.\n\nReturns\n\nAbstractVector{T}: The computed control input vector.\n\nDescription\n\nThis function computes the control input for the MAController by selecting the appropriate control law from the Ks collection based on the current internal state z and the reward signals rs. The selection is made using the selectionRule of the controller.\n\n\n\n\n\n","category":"method"},{"location":"lib/bellman/#MinimaxAdaptiveControl.getPeriodicSelectionRule","page":"Bellman Inequalities","title":"MinimaxAdaptiveControl.getPeriodicSelectionRule","text":"getPeriodicSelectionRule(period::Int)\n\nCreate a selection rule for periodic control.\n\nArguments\n\nperiod::Int: Control period.\n\nReturns\n\nselectionRule::Function: A function that selects the index of the control input based on the period and reward signals.\n\nExample\n\nselectionRule = getPeriodicSelectionRule(4)\nindex = selectionRule(z, rs)\n\n\n\n\n\n","category":"function"},{"location":"lib/bellman/#MinimaxAdaptiveControl.getValueFunction","page":"Bellman Inequalities","title":"MinimaxAdaptiveControl.getValueFunction","text":"getValueFunction(mac::MAController{T}, Ps0::Dict{Tuple{Int, Int}, Matrix{VariableRef}}, N::Int) where T<:Real\n\nCreate a ValueFunction for the given multi-agent controller and positive semi-definite matrices.\n\nArguments\n\nmac::MAController{T}: Minimax adaptive controller.\nPs0::Dict{Tuple{Int, Int}, Matrix{VariableRef}}: Dictionary of positive semi-definite matrices associated with the first time step in each period.\nN::Int: Number of models.\n\nReturns\n\nValueFunction: A value function object for the multi-agent controller.\n\nExample\n\nvfun = getValueFunction(mac, Ps0, N)\n\n\n\n\n\n","category":"function"},{"location":"lib/bellman/#MinimaxAdaptiveControl.update!-Union{Tuple{T}, Tuple{MAController{T}, AbstractVector{T}, AbstractVector{T}}} where T<:Real","page":"Bellman Inequalities","title":"MinimaxAdaptiveControl.update!","text":"update!(controller::MAController{T}, output::AbstractVector{T}, control::AbstractVector{T}) where T<:Real\n\nUpdate the multi-agent controller with new output and control data.\n\nArguments\n\ncontroller::MAController{T}: The multi-agent controller to be updated.\noutput::AbstractVector{T}: The new output measurement vector.\ncontrol::AbstractVector{T}: The new control input vector.\n\nDescription\n\nThis function updates the internal state z and the reward signals rs of the MAController based on the new output and control input data. The reward signals are updated for each matrix H in the controller's Hs collection. The internal state z is updated using the estimated system matrices Ahat, Bhat, and Ghat.\n\n\n\n\n\n","category":"method"},{"location":"#Minimax-Adaptive-Control","page":"Home","title":"Minimax Adaptive Control","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Companion code for the paper Output Feedback Minimax Adaptive Control (Image: Image for minimax adaptive control)","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = MinimaxAdaptiveControl","category":"page"},{"location":"examples/output_feedback/#Output-feedback-with-approximate-pole-cancellation","page":"Output feedback","title":"Output feedback with approximate pole cancellation","text":"","category":"section"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"This example compares the minimax adaptive controller to the self-tuning LQG controller.","category":"page"},{"location":"examples/output_feedback/#Introduction","page":"Output feedback","title":"Introduction","text":"","category":"section"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"The minimum phase system, G_textmp, and the nonminimum-phase system, G_textnmp, have state-space realizations (A B C_textmp D G) and (A B C_textnmp D G) respectively, where","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"\tbeginaligned\n\t\tA  = beginbmatrix1  1 0  1endbmatrix  B  = beginbmatrix0  1endbmatrix \n\t\tC_textmp  = beginbmatrix-1z_0 + z_0  z_0endbmatrix^top  C_textnmp  = beginbmatrix-z_0 + 1z_0  1z_0endbmatrix^top\n\tendaligned","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"Here z_0 = 101, G = I  100 and D = 110. The goal is to synthesize a controller mu that, for as small a gamma  0 as possible, minimizes","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"sup_C w v N sum_t = 0^N left(x_t^2_Q + u_t^2_R - gamma^2 (w_t v_t)^2 right)","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"where Q = I and R = I100.","category":"page"},{"location":"examples/output_feedback/#Preliminaries","page":"Output feedback","title":"Preliminaries","text":"","category":"section"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"Load the packages","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"using MinimaxAdaptiveControl\nusing LinearAlgebra, Random\nusing JuMP \nusing Clarabel ","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"and define the optimizer_factory to be used throughout","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"optimizer_factory = () -> Clarabel.Optimizer","category":"page"},{"location":"examples/output_feedback/#Controller-synthesis","page":"Output feedback","title":"Controller synthesis","text":"","category":"section"},{"location":"examples/output_feedback/#Minimax-Adaptive-Controller","page":"Output feedback","title":"Minimax Adaptive Controller","text":"","category":"section"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"We first define the nominal models","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"a = 1.01\nA = [1.0 1.0; 0.0 1.0]\nB1 = [0.0 1.0]'\nB2 = [0.0 1.0]'\nC1 = [-a + 1/a 1/a]\nC2 = [-1/a + a a]\nD = fill(1.0,1,1) / 10\nG = [1.0 0; 0 1.0] / 100\nQ = [1.0 0; 0 1.0] / 100\nR = fill(1.0,1,1) / 100\nγ = 20.0\nsys1 = OFLinMod(A, B1, G, C1, D, Q, R)\nsys2 = OFLinMod(A, B2, G, C2, D, Q, R)\nsys = [sys1, sys2]","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"We next reduce the system to principal form using reduceSys","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"models = [Model(optimizer_factory()), Model(optimizer_factory())]\n(A, B, G, Ks, Hs) = reduceSys(sys, γ, models)","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"and check the termination statuses as a first test that gamma is not too small.","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"julia> termination_status.(models)\n2-element Vector{MathOptInterface.TerminationStatusCode}:\n OPTIMAL::TerminationStatusCode = 1\n OPTIMAL::TerminationStatusCode = 1","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"Next, we solve the periodic bellman inequalities with a period tau = 4","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"model = Model(optimizer_factory())\nset_silent(model)\nperiod = 4\nPs0, Psplus= MACLMIs(A, B, G, Ks, Hs, period, model)","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"and verify that gamma is a valid upper bound","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"julia> termination_status(model)\nOPTIMAL::TerminationStatusCode = 1","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"Next we synthesize the selection rule using getPeriodicSelectionRule and the controller using MAController","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"N = length(Hs) # = 2\nselectionRule = getPeriodicSelectionRule(period)\nmac = MAController(zeros(4), A, B, G, Ks, Hs, zeros(N), selectionRule)","category":"page"},{"location":"examples/output_feedback/#Self-tuning-regulator:-certainty-equivalence-LQG","page":"Output feedback","title":"Self-tuning regulator: certainty equivalence LQG","text":"","category":"section"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"We will construct a SelfTuningLQG object with randomized initial estimates:","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"A0 = randn(2, 2)\nB0 = randn(2, 1)\nC0 = randn(1, 2)\nK0 = randn(2, 1)\nS0 = Matrix{Float64}(I(2))\nL0 = zeros(1, 2)\nQ0 = Matrix{Float64}(I(2))\nρ0 = 1.0\nxhat0 = randn(2)\nnu = 2\nstr = SelfTuningLQG(A0, K0, C0, B0, xhat0, 0.0, 1.0, nu)","category":"page"},{"location":"examples/output_feedback/#Simulation","page":"Output feedback","title":"Simulation","text":"","category":"section"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"We will simulate for","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"Tdur = 2000","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"steps. We define two equivalent simulation models as OFPlant objects:","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"Asim = [1.0 1.0; 0.0 1.0]\nBsim = [0.0 1.0]'\nCsim = [-a + 1/a 1/a]\nDsim = fill(1.0,1,1) / 10\nGsim = [1.0 0; 0 1.0] / 100\nQsim = [1.0 0; 0 1.0] / 100\nRsim = fill(1.0,1,1) / 100\nplantMAC= OFPlant(Asim, Bsim, Gsim, Csim, Dsim, zeros(2))\nplantSTR = OFPlant(Asim, Bsim, Gsim, Csim, Dsim, zeros(2))","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"Both simulations will be affected by the same process and measurement noise","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"processDisturbances = randn(Tdur, 2)\nmeasurementDisturbances = randn(Tdur, 1)","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"Next we construct matrices to store the state, input, output and metric trajectories","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"statesMAC = zeros(Tdur + 1, 2)\nstatesSTR = zeros(Tdur + 1, 2)\noutputsMAC = zeros(Tdur + 1, 1)\noutputsSTR = zeros(Tdur + 1, 1)\ncontrolsMAC = zeros(Tdur, 1)\ncontrolsSTR = zeros(Tdur, 1)\nvfunMAC = getValueFunction(mac, Ps0, N)\ndcMAC = InducedlpGain(0.0, 0.0, 0.0, 2)\ndcSTR = InducedlpGain(0.0, 0.0, 0.0, 2)\nmetricsMAC = [vfunMAC, dcMAC]\nmetricsSTR = [dcSTR]\nmetricResultsMAC = zeros(Tdur + 1, length(metricsMAC))\nmetricResultsSTR = zeros(Tdur + 1, length(metricsSTR))","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"Finally we run the simulations","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"simulate!(statesMAC, outputsMAC, controlsMAC, processDisturbances, measurementDisturbances, metricResultsMAC, metricsMAC, plantMAC, mac, Tdur)\nsimulate!(statesSTR, outputsSTR, controlsSTR, processDisturbances, measurementDisturbances, metricResultsSTR, metricsSTR, plantSTR, str, Tdur)","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"and plot the results","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"plt = plot(layout = (2, 3), size = (800, 600))\nplot!(plt[1], statesMAC, xlabel = \"Timestep\", label = [\"State 1\" \"State 2\"], linewidth = 2, legend = :topright)\nplot!(plt[2], controlsMAC, xlabel = \"Timestep\", ylabel = \"Control\", label = \"Control\", linewidth = 2)\nplot!(plt[3], metricResultsMAC[1:end-1, 2], xlabel = \"Timestep\", ylabel = \"Induced Lp Gain\", label = \"Induced Lp Gain\", linewidth = 2)\nplot!(plt[4], statesSTR, xlabel = \"Timestep\", label = [\"State 1\" \"State 2\"], linewidth = 2)\nplot!(plt[5], controlsSTR, xlabel = \"Timestep\", ylabel = \"Control\", label = \"Control\", linewidth = 2)\nplot!(plt[6], metricResultsSTR[1:end-1, 1], xlabel = \"Timestep\", ylabel = \"Induced Lp Gain\", label = \"Induced Lp Gain\", linewidth = 2)","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"(Image: Comparison of the states, controls and metrics)","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"We also plot the valubound and highlight that it's periodically nonincreasing","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"\nplot(1:numPeriods*period, metricResultsMAC[1:numPeriods*period, 1], linestyle = :solid, linewidth = 2, color = :black, label = \"Vbar\")\nplot!(inds[1:numPeriods], metricResultsMAC[inds[1:numPeriods], 1], xlabel = \"Timestep\", ylabel = \"Value Function\", label = \"Periodic Vbar\", linewidth = 2, linestyle = :dash, color = :blue, marker = :circle)","category":"page"},{"location":"examples/output_feedback/","page":"Output feedback","title":"Output feedback","text":"(Image: Periodic value function)","category":"page"},{"location":"lib/simulation/","page":"Simulation","title":"Simulation","text":"Pages = [\"simulation.md\"]","category":"page"},{"location":"lib/simulation/","page":"Simulation","title":"Simulation","text":"evaluate(v::AbstractPerformanceMetric{T}) where T<:Real\nobserve(plant::SSPlant{T}, measurementDisturbance::AbstractVector{T}) where T<:Real\nobserve(plant::OFPlant{T}, measurementDisturbance::AbstractVector{T}) where T<:Real\nsimulate!\nupdate!(plant::SSPlant{T}, controls::AbstractVector{T}, processDisturbances::AbstractVector{T}) where T<:Real\nupdate!(plant::OFPlant{T}, controls::AbstractVector{T}, processDisturbances::AbstractVector{T}) where T<:Real\nupdate(id::InducedlpGain{T, N}, input::AbstractVector{T}, output::AbstractVector{T}) where T<:Real where N<:Integer\nupdate(v::ValueFunction{T}, input::AbstractVector{T}, output::AbstractVector{T}) where T<:Real","category":"page"},{"location":"lib/simulation/#MinimaxAdaptiveControl.evaluate-Union{Tuple{AbstractPerformanceMetric{T}}, Tuple{T}} where T<:Real","page":"Simulation","title":"MinimaxAdaptiveControl.evaluate","text":"evaluate(v::AbstractPerformanceMetric{T}) where T<:Real\n\nEvaluate the value of a performance metric.\n\nArguments\n\nv::AbstractPerformanceMetric{T}: The performance metric to be evaluated.\n\nReturns\n\nT: The value of the performance metric.\n\n\n\n\n\n","category":"method"},{"location":"lib/simulation/#MinimaxAdaptiveControl.observe-Union{Tuple{T}, Tuple{SSPlant{T}, AbstractVector{T}}} where T<:Real","page":"Simulation","title":"MinimaxAdaptiveControl.observe","text":"observe(plant::SSPlant{T}, measurementDisturbance::AbstractVector{T}) where T<:Real\n\nObserve the output of a state-space plant given measurement disturbances.\n\nArguments\n\nplant::SSPlant{T}: The state-space plant.\nmeasurementDisturbance::AbstractVector{T}: The measurement disturbance vector.\n\nReturns\n\nVector{T}: The observed output vector.\n\n\n\n\n\n","category":"method"},{"location":"lib/simulation/#MinimaxAdaptiveControl.observe-Union{Tuple{T}, Tuple{OFPlant{T}, AbstractVector{T}}} where T<:Real","page":"Simulation","title":"MinimaxAdaptiveControl.observe","text":"observe(plant::OFPlant{T}, measurementDisturbance::AbstractVector{T}) where T<:Real\n\nObserve the output of an output-feedback plant given measurement disturbances.\n\nArguments\n\nplant::OFPlant{T}: The output-feedback plant.\nmeasurementDisturbance::AbstractVector{T}: The measurement disturbance vector.\n\nReturns\n\nVector{T}: The observed output vector.\n\nExample\n\n\n\n\n\n","category":"method"},{"location":"lib/simulation/#MinimaxAdaptiveControl.simulate!","page":"Simulation","title":"MinimaxAdaptiveControl.simulate!","text":"simulate!(states::AbstractMatrix{T}, outputs::AbstractMatrix{T}, controls::AbstractMatrix{T},\n          processDisturbances::AbstractMatrix{T}, measurementDisturbances::AbstractMatrix{T},\n          metricResults::AbstractMatrix{X}, metrics::AbstractVector{M}, plant::AbstractPlant{T},\n          controller::AbstractController{T}, duration::N) where T<:Real where N<:Integer where M <: AbstractPerformanceMetric where X\n\nSimulate the control system for a given duration, updating states, outputs, controls, and metrics.\n\nArguments\n\nstates::AbstractMatrix{T}: Matrix to store the state vectors over time.\noutputs::AbstractMatrix{T}: Matrix to store the output vectors over time.\ncontrols::AbstractMatrix{T}: Matrix to store the control vectors over time.\nprocessDisturbances::AbstractMatrix{T}: Matrix of process disturbance vectors.\nmeasurementDisturbances::AbstractMatrix{T}: Matrix of measurement disturbance vectors.\nmetricResults::AbstractMatrix{X}: Matrix to store metric evaluation results.\nmetrics::AbstractVector{M}: Vector of performance metrics to be evaluated.\nplant::AbstractPlant{T}: The plant model being controlled.\ncontroller::AbstractController{T}: The controller used to control the plant.\nduration::N: The duration for which the simulation runs.\n\nDescription\n\nThis function simulates the control system over the specified duration. It updates the plant states, controller, and performance metrics at each time step.\n\nExample\n\n\n\n\n\n","category":"function"},{"location":"lib/simulation/#MinimaxAdaptiveControl.update!-Union{Tuple{T}, Tuple{SSPlant{T}, AbstractVector{T}, AbstractVector{T}}} where T<:Real","page":"Simulation","title":"MinimaxAdaptiveControl.update!","text":"update!(plant::SSPlant{T}, controls::AbstractVector{T}, processDisturbances::AbstractVector{T}) where T<:Real\n\nUpdate the state of a state-space plant given control inputs and process disturbances.\n\nArguments\n\nplant::SSPlant{T}: The state-space plant to be updated.\ncontrols::AbstractVector{T}: The control input vector.\nprocessDisturbances::AbstractVector{T}: The process disturbance vector.\n\nReturns\n\nVector{T}: The updated state vector.\n\n\n\n\n\n","category":"method"},{"location":"lib/simulation/#MinimaxAdaptiveControl.update!-Union{Tuple{T}, Tuple{OFPlant{T}, AbstractVector{T}, AbstractVector{T}}} where T<:Real","page":"Simulation","title":"MinimaxAdaptiveControl.update!","text":"update!(plant::OFPlant{T}, controls::AbstractVector{T}, processDisturbances::AbstractVector{T}) where T<:Real\n\nUpdate the state of an output-feedback plant given control inputs and process disturbances.\n\nArguments\n\nplant::OFPlant{T}: The output-feedback plant to be updated.\ncontrols::AbstractVector{T}: The control input vector.\nprocessDisturbances::AbstractVector{T}: The process disturbance vector.\n\nReturns\n\nVector{T}: The updated state vector.\n\n\n\n\n\n","category":"method"},{"location":"lib/simulation/#MinimaxAdaptiveControl.update-Union{Tuple{T}, Tuple{N}, Tuple{InducedlpGain{T, N}, AbstractVector{T}, AbstractVector{T}}} where {N<:Integer, T<:Real}","page":"Simulation","title":"MinimaxAdaptiveControl.update","text":"update(id::InducedlpGain{T, N}, input::AbstractVector{T}, output::AbstractVector{T}) where T<:Real where N<:Integer\n\nUpdate the induced l_p gain metric with new input and output data.\n\nArguments\n\nid::InducedlpGain{T, N}: The induced l_p gain metric to be updated.\ninput::AbstractVector{T}: The input vector.\noutput::AbstractVector{T}: The output vector.\n\nReturns\n\nInducedlpGain{T, N}: The updated induced l_p gain metric.\n\n\n\n\n\n","category":"method"},{"location":"lib/simulation/#MinimaxAdaptiveControl.update-Union{Tuple{T}, Tuple{ValueFunction{T}, AbstractVector{T}, AbstractVector{T}}} where T<:Real","page":"Simulation","title":"MinimaxAdaptiveControl.update","text":"update(v::ValueFunction{T}, input::AbstractVector{T}, output::AbstractVector{T}) where T<:Real\n\nUpdate the value function with new input and output data.\n\nArguments\n\nv::ValueFunction{T}: The value function to be updated.\ninput::AbstractVector{T}: The input vector.\noutput::AbstractVector{T}: The output vector.\n\nReturns\n\nValueFunction{T}: The updated value function.\n\n\n\n\n\n","category":"method"}]
}
